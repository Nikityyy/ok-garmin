<!DOCTYPE html>
<html lang="de">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Garmin Assistant</title>
    <meta name="theme-color" content="#e60000">
    <link rel="manifest" href="/static/manifest.json">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="apple-mobile-web-app-title" content="Garmin">

    <style>
        :root {
            --background-color: #f4f4f4;
            --text-color: #111111;
            --accent-color: #e60000;
            --muted-color: #888888;
        }

        body {
            margin: 0;
            padding: 2rem;
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol";
            background-color: var(--background-color);
            color: var(--text-color);
            display: flex;
            justify-content: center;
            align-items: center;
            min-height: calc(100vh - 4rem);
            font-size: 16px;
        }

        #app-container {
            max-width: 700px;
            width: 100%;
            height: calc(100vh - 4rem);
            display: grid;
            grid-template-rows: auto auto 1fr;
            gap: 1rem;
        }

        header {
            border-bottom: 1px solid var(--muted-color);
            padding-bottom: 1rem;
        }

        header h1 {
            font-size: 2.5rem;
            font-weight: 600;
            margin: 0;
            letter-spacing: -1px;
        }
        
        main {
            display: flex;
            flex-direction: column;
            overflow: hidden;
        }

        #visualizer-container {
            display: flex;
            justify-content: center;
            align-items: center;
            height: 80px;
            margin-bottom: 1rem;
            flex-shrink: 0;
        }

        #visualizer {
            width: 50px;
            height: 50px;
            background-color: var(--muted-color);
            border-radius: 50%;
            transition: all 0.3s ease;
        }

        #visualizer.active {
            background-color: var(--accent-color);
            animation: pulse 1.5s infinite ease-in-out;
        }

        @keyframes pulse {
            0% { transform: scale(0.9); opacity: 0.7; }
            50% { transform: scale(1); opacity: 1; }
            100% { transform: scale(0.9); opacity: 0.7; }
        }

        .status-text {
            text-align: center;
            font-size: 1.2rem;
            color: var(--muted-color);
            height: 2em;
            flex-shrink: 0;
        }
        
        #conversation-log {
            font-size: 1.5rem;
            line-height: 1.6;
            overflow-y: auto;
            padding-right: 1rem;
            word-wrap: break-word;
        }

        #conversation-log .user {
            color: var(--muted-color);
        }
        
        #conversation-log .assistant {
            font-weight: 500;
            color: var(--text-color);
            margin-bottom: 1.5em;
        }

        #permission-modal {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background-color: rgba(0, 0, 0, 0.7);
            display: flex;
            justify-content: center;
            align-items: center;
            z-index: 1000;
            color: white;
            text-align: center;
        }

        #permission-modal button {
            font-size: 1.5rem;
            padding: 1rem 2rem;
            background-color: var(--accent-color);
            color: white;
            border: none;
            cursor: pointer;
            border-radius: 5px;
        }

    </style>
</head>
<body>

    <div id="app-container">
        <header>
            <h1>Garmin</h1>
        </header>
        <main>
            <div id="visualizer-container">
                <div id="visualizer"></div>
            </div>
            <p id="status" class="status-text">Verbindung wird hergestellt...</p>
            <div id="conversation-log">
            </div>
        </main>
    </div>

    <div id="permission-modal">
        <div>
            <h2>Mikrofonzugriff erforderlich</h2>
            <p>Klicken Sie, um den Assistenten zu starten.</p>
            <button id="start-button">Starten</button>
        </div>
    </div>

    <script>
    document.addEventListener('DOMContentLoaded', () => {
        const startButton = document.getElementById('start-button');
        const permissionModal = document.getElementById('permission-modal');
        const statusEl = document.getElementById('status');
        const visualizerEl = document.getElementById('visualizer');
        const conversationLogEl = document.getElementById('conversation-log');

        // This URL will dynamically take the PC's IP address if accessed via IP
        const WEBSOCKET_URL = `ws://${window.location.host}/ws`; 
        let ws;
        let audioContext;
        let scriptNode;
        let mediaStream;

        // --- Audio Playback State ---
        let audioQueue = [];
        let isPlayingAudio = false;
        let nextChunkStartTime = 0;
        let currentAudioSource = null;
        let ttsStreamHasEnded = false;


        startButton.addEventListener('click', () => {
            permissionModal.style.display = 'none';
            init();
        });

        function updateStatus(text, isActive = false) {
            statusEl.textContent = text;
            if (isActive) {
                visualizerEl.classList.add('active');
            } else {
                visualizerEl.classList.remove('active');
            }
        }
        
        function showUserTranscript(text) {
            const userP = document.createElement('p');
            userP.textContent = text;
            userP.className = 'user';
            conversationLogEl.appendChild(userP);

            const assistantP = document.createElement('p');
            assistantP.className = 'assistant';
            conversationLogEl.appendChild(assistantP);
            
            conversationLogEl.scrollTop = conversationLogEl.scrollHeight;
        }

        function appendToAssistantResponse(chunk) {
            let assistantP = conversationLogEl.querySelector('p.assistant:last-child');
            if (assistantP) {
                assistantP.textContent += chunk;
                conversationLogEl.scrollTop = conversationLogEl.scrollHeight;
            }
        }

        function resetAudioState() {
            audioQueue = [];
            isPlayingAudio = false;
            nextChunkStartTime = 0;
            if (currentAudioSource) {
                try { currentAudioSource.stop(); } catch(e) {}
            }
            currentAudioSource = null;
            ttsStreamHasEnded = false;
        }

        function onAllAudioFinished() {
            console.log("All audio playback finished.");
            resetAudioState();
            if (ws && ws.readyState === WebSocket.OPEN) {
                ws.send(JSON.stringify({ type: 'audio_finished' }));
            }
        }

        async function playAudioQueue() {
            if (audioQueue.length === 0) {
                if (ttsStreamHasEnded) {
                    onAllAudioFinished();
                }
                return;
            }
            
            isPlayingAudio = true;
            
            if (audioContext.state === 'suspended') await audioContext.resume();

            const chunkBuffer = audioQueue.shift();
            
            try {
                const decodedBuffer = await audioContext.decodeAudioData(chunkBuffer);
                const source = audioContext.createBufferSource();
                source.buffer = decodedBuffer;
                source.connect(audioContext.destination);
                currentAudioSource = source;

                const currentTime = audioContext.currentTime;
                const startTime = Math.max(currentTime, nextChunkStartTime);
                
                source.start(startTime);
                nextChunkStartTime = startTime + decodedBuffer.duration;

                source.onended = () => {
                    isPlayingAudio = false;
                    currentAudioSource = null;
                    playAudioQueue();
                };
            } catch (e) {
                console.error("Error decoding audio chunk:", e);
                isPlayingAudio = false;
                playAudioQueue();
            }
        }

        async function init() {
            try {
                updateStatus('Mikrofon wird initialisiert...');
                audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 16000 });
                
                if (!audioContext.createScriptProcessor) {
                   audioContext.createScriptProcessor = audioContext.createJavaScriptNode;
                }

                mediaStream = await navigator.mediaDevices.getUserMedia({ audio: true, video: false });
                const source = audioContext.createMediaStreamSource(mediaStream);
                
                const bufferSize = 4096;
                scriptNode = audioContext.createScriptProcessor(bufferSize, 1, 1);

                scriptNode.onaudioprocess = (audioProcessingEvent) => {
                    if (ws && ws.readyState === WebSocket.OPEN) {
                        const pcmData = audioProcessingEvent.inputBuffer.getChannelData(0);
                        const int16Data = new Int16Array(pcmData.length);
                        for (let i = 0; i < pcmData.length; i++) {
                            int16Data[i] = Math.max(-1, Math.min(1, pcmData[i])) * 32767;
                        }
                        ws.send(int16Data.buffer);
                    }
                };
                
                source.connect(scriptNode);
                scriptNode.connect(audioContext.destination);

                connectWebSocket();

            } catch (err) {
                console.error('Error initializing audio:', err);
                updateStatus('Fehler: Mikrofonzugriff verweigert.');
                permissionModal.style.display = 'flex';
            }
        }

        function connectWebSocket() {
            ws = new WebSocket(WEBSOCKET_URL);
            ws.binaryType = 'arraybuffer';

            ws.onopen = () => {
                console.log('WebSocket connected.');
                updateStatus('Ich höre zu...');
            };

            ws.onmessage = (event) => {
                if (event.data instanceof ArrayBuffer) {
                    audioQueue.push(event.data);
                    if (!isPlayingAudio) {
                        playAudioQueue();
                    }
                    return;
                }
                
                const data = JSON.parse(event.data);
                console.log('Received message:', data);

                switch (data.type) {
                    case 'status':
                        updateStatus(data.message, data.isActive);
                        break;
                    case 'user_transcript':
                        resetAudioState();
                        showUserTranscript(data.data);
                        break;
                    case 'llm_chunk':
                        appendToAssistantResponse(data.data);
                        break;
                    case 'llm_end':
                        break;
                    case 'tts_stream_end':
                        ttsStreamHasEnded = true;
                        if (!isPlayingAudio && audioQueue.length === 0) {
                            onAllAudioFinished();
                        }
                        break;
                    case 'stop_audio':
                        console.log('Interruption: Stopping audio playback.');
                        resetAudioState();
                        break;
                }
            };

            ws.onclose = () => {
                console.log('WebSocket disconnected.');
                updateStatus('Verbindung verloren. Erneut verbinden...', false);
                setTimeout(connectWebSocket, 3000); 
            };

            ws.onerror = (error) => {
                console.error('WebSocket error:', error);
                updateStatus('Verbindungsfehler.', false);
            };
        }

        if ('serviceWorker' in navigator) {
            window.addEventListener('load', () => {
                navigator.serviceWorker.register('/static/sw.js')
                    .then(registration => {
                        console.log('Service Worker registered with scope:', registration.scope);
                    })
                    .catch(error => {
                        console.error('Service Worker registration failed:', error);
                    });
            });
        }
    });
    </script>
</body>
</html>
